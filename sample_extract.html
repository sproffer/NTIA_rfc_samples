<html>
<head>
<title>NTIA PUBLIC COMMENTS</title>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<style>
h1 {
    text-align: center;
	font: 26px arial,helvetica,sans-serif;
}
h2 {
    text-align: left;
	font: 20px arial,helvetica,sans-serif;
}
h3 {
    text-align: left;
    font: 16px arial,helvetica,sans-serif;
    font-weight:600;
}
div { margin-left: 10; }
body {
    margin:10px; padding:0px; font: arial,helvetica,sans-serif;
}
</style>
</head>
<body>
<h1>NTIA Public Comments</h1>
<div style="margin:20">

<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-1233" target=_blank>NTIA-2023-0005-1233</a> </h2>
<div >
<h3>online comments </h3>
BCBSA comments attached
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-1233/attachment_1.pdf' download>attached document</a></h3>
- Alan Davidson is the Administrator of the National Telecommunications and Information Administration (NTIA) in the U.S. Department of Commerce.<br/>- BCBSA is providing comments on the AI Accountability Policy RFC.<br/>- BCBSA is a national federation of 34 independent, community-based and locally operated Blue Cross and Blue Shield (BCBS) companies.<br/>- BCBSA believes in ensuring access to high-quality healthcare for everyone.<br/>- BCBSA commends NTIA for engaging on the topic of AI accountability.<br/>- BCBSA is committed to improving the way they gain insight from diverse health factors and use technologies.<br/>- BCBSA offers comments to the RFC on AI accountability policy development.<br/>- NTIA's RFC aligns with NIST's AI Risk Management Framework (RMF).<br/>- NTIA should encourage federal regulatory agencies to align on enforceable requirements for AI regulation.<br/>- The comments provided by BCBSA are appreciated and believed to be helpful in the development and use of trustworthy AI through sensible public policies.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-1144" target=_blank>NTIA-2023-0005-1144</a> </h2>
<div >
<h3>online comments </h3>
See attached file(s)
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-1144/attachment_1.pdf' download>attached document</a></h3>
- The AI Risk and Vulnerability Alliance (ARVA) focuses on identifying and managing vulnerabilities in AI systems.<br/>- Their main project is the AI Vulnerability Database (AVID), which combines a taxonomy of AI risks with an open-source knowledge base of flaws in AI systems and mitigation techniques.<br/>- ARVA believes that lessons from cybersecurity can be applied to the AI accountability ecosystem.<br/>- AVID is being developed as an open-source repository for the disclosure of social and technical vulnerabilities in AI systems.<br/>- ARVA emphasizes the need for a robust adjudication process for AI vulnerabilities, involving multi-stakeholder standard setting and a transparent editorial process.<br/>- They support the development of standardized reporting formats and centralized repositories for AI vulnerabilities, similar to the Common Vulnerabilities and Exposures (CVE) system in cybersecurity.<br/>- Standardized reporting formats and repositories enable communication, collaboration, interoperability, and analysis of vulnerabilities.<br/>- ARVA suggests that vulnerabilities should be disclosed ethically, with companies being informed before public disclosure when possible.<br/>- They highlight the importance of an adjudicating body to handle disclosures and translate technical reports or audits for affected communities.<br/>- ARVA aims to co-create resources with communities to make AI less harmful and is available for further assistance.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-1108" target=_blank>NTIA-2023-0005-1108</a> </h2>
<div >
<h3>online comments </h3>
See attached file(s)
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-1108/attachment_1.pdf' download>attached document</a></h3>
- The content discusses worldwide government affairs and policy, focusing on the interaction between governments and policies on a global scale.<br/>- It covers various aspects of government affairs and policy, including international relations, diplomacy, and governance.<br/>- The content provides specific information about Travis Hall, the Acting Deputy Associate Commissioner of the National Telecommunications and Information Administration (NTIA) within the US Department of Commerce.<br/>- The NTIA is responsible for advising the President on telecommunications and information policy issues.<br/>- The content mentions an AI accountability policy for a specific request for comment docket number (230407-0093).<br/>- Johnson & Johnson (J&J) is submitting input on the AI Accountability Policy Request for Comment and supports the goal of trustworthy, ethical, and equitable application of AI.<br/>- J&J is the world's leading manufacturer of healthcare products and believes that AI can improve healthcare and address industry challenges.<br/>- J&J uses AI for drug discovery, optimizing surgical instruments and implants, and identifying rare adverse events.<br/>- J&J approaches AI in an ethical, compliant, and secure manner, guided by their Credo, Business Code of Conduct, and Ethical Code for the Conduct of Research and Development.<br/>- The content emphasizes the importance of ethical principles in AI development and use, including transparency, integrity, and respect for rights and welfare.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-1096" target=_blank>NTIA-2023-0005-1096</a> </h2>
<div >
<h3>online comments </h3>
Please see attached file
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-1096/attachment_1.pdf' download>attached document</a></h3>
- The response was submitted on June 12, 2023.<br/>- The response is in reference to the NTIA AI Accountability Policy Request for Comment.<br/>- The content of the response is not provided.<br/>- Artificial intelligence technologies are being integrated into consumer technology without sufficient consideration of risks and impacts.<br/>- Companies should prioritize transparency, accountability, and ethical participation in AI development and use.<br/>- Companies publishing APIs should disclose data sources and training methods.<br/>- Generative AI should have clear rules for addressing harm, evaluated by a diverse group.<br/>- Third-party audits should be allowed for large language models.<br/>- Clear objectives, measurable outcomes, and ethical considerations are important in AI development.<br/>- OSHA-like rules are proposed to protect workers involved in training models and labeling data.<br/>- Repeated exposure to harmful content can have negative effects on health.<br/>- Companies should disclose the use of large language models in API interfaces.<br/>- Understanding how AI models arrive at outputs is a challenge.<br/>- Companies should articulate their approach to the use of AI systems and comply with requests for information.<br/>- The NTIA should address antitrust, copyright, and human rights protections in AI accountability requirements.<br/>- The NTIA has the opportunity to promote fairness and competition in the technology industry.<br/>- Lawsuits and allegations against AI companies have been filed regarding underpayment and toxic content filtering.<br/>- Olivia Erickson is a co-founder of iamagoodbing.ai and an Executive MBA candidate at Columbia Business School.<br/>- M Eifler is the founder of BlinkPopShift, but no further details are provided.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0108" target=_blank>NTIA-2023-0005-0108</a> </h2>
<div >
<h3>online comments </h3>
Please find attached, I am giving some explanation/examples on my thinking, the reason I propose these.
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-0108/attachment_1.pdf' download>attached document</a></h3>
- AI should not be involved in decision-making processes in government, legislature, court, and judicial processes.<br/>- AI algorithms may harm marginalized people despite increasing GDP.<br/>- Human-run government is necessary for democracy, despite inefficiencies.<br/>- AI should not replace human jury selection and participation in the judicial process.<br/>- Human interaction is more effective than AI in school counseling, especially with youths.<br/>- AI should not shape kids' mindset with the ideology of its creators or unpredictable views.<br/>- The use of AI in areas like mental health products should be debated.<br/>- AI-generated contents must be labeled as such in major media to prevent misinformation and political manipulation.<br/>- Labeling requirements should be mandated for content publishing parties to differentiate AI-generated content from human-created content.<br/>- Private funded third-party auditors should be used to audit AI systems, similar to financial audits, to ensure compliance with policy requirements.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-1200" target=_blank>NTIA-2023-0005-1200</a> </h2>
<div >
<h3>online comments </h3>
See attached file.
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-1200/attachment_1.pdf' download>attached document</a></h3>
- User expresses gratitude for the opportunity to provide input on AI accountability policy.<br/>- The Investor Alliance for Human Rights focuses on responsible investment and respecting human rights.<br/>- Rapid development of AI without human rights due diligence has led to adverse impacts.<br/>- Harms include misinformation, hate speech, illegal surveillance, attacks on democracy, censorship, and discrimination.<br/>- These harms pose financial, legal, and reputational risks to companies and investors.<br/>- Global regulations are needed to incentivize responsible development and use of AI.<br/>- The Investor Alliance supports robust digital rights regulations like the proposed EU AI Act.<br/>- Trustworthy AI should be grounded in human rights principles and include mandatory due diligence.<br/>- Stakeholder and rightsholder participation is important for safe development of AI.<br/>- Regulations should prioritize transparency, fairness, and accountability.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-1238" target=_blank>NTIA-2023-0005-1238</a> </h2>
<div >
<h3>online comments </h3>
See attachment
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-1238/attachment_1.pdf' download>attached document</a></h3>
- Patient care systems in America and globally have been found to be unsafe, ineffective, and biased.<br/>- The blueprint for an AI Bill of Rights aims to establish a set of rights and principles to govern the development and use of artificial intelligence (AI) technologies.<br/>- The Prescription Drug Monitoring Program (PDMP) created by Bamboo Health has led to the weaponization of algorithms and data collection.<br/>- The proprietary algorithms used in the PDMP are not regulated by the federal government as a clinical decision-making tool.<br/>- The Center for U.S. Policy has petitioned for the classification of Bamboo Health's NarxCare algorithms as a medical device subject to FDA regulation.<br/>- The FDA is considering how to regulate software used in medical devices and seeking public input on the issue.<br/>- The article titled "Dosing Discrimination: Regulating PDMP Risk Scores" by Professor Jennifer D. Oliva provides a legal analysis of PDMP discrimination and harm.<br/>- The practice of medicine is being criminalized, leading to the incarceration of physicians and the denial of clinically indicated medications to patients.<br/>- PDMP surveillance algorithms put lives at risk instead of saving them, and further surveillance has not been successful in saving lives.<br/>- The National AI Initiative Act of 2020 established federal priorities for AI and created the National AI Initiative Office.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-1242" target=_blank>NTIA-2023-0005-1242</a> </h2>
<div >
<h3>online comments </h3>
Please see attached file.
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-1242/attachment_1.pdf' download>attached document</a></h3>
- Accenture provides professional services including data and AI, cloud, and security.<br/>- They have an Applied Intelligence practice that focuses on AI applications and Responsible AI.<br/>- Accenture Federal Services emphasizes the importance of a well-designed AI governance framework.<br/>- Human participation and decision tracing are crucial in AI systems.<br/>- Baseline accountability measures should be included in the design stage.<br/>- Feedback tools like guardrails and model self-validation can refine AI models.<br/>- Accenture supports NTIA's efforts in developing AI accountability measures.<br/>- Certifications, audits, and assessments promote trust and change internal processes.<br/>- Baseline measures based on human performance should be established for AI.<br/>- AI accountability mechanisms should address systemic risks and bias mitigation.<br/><br/>- Human participation is important in addressing bias and making judgments in AI systems.<br/>- Technical approaches like guardrails and model self-validation can refine AI models.<br/>- Adversarial attacks should be considered and countermeasures implemented.<br/>- Flexible guiding principles should govern AI with nuance and flexibility.<br/>- Accountability mechanisms for generative AI tools should consider the broader context.<br/>- The organization designing and operating the tool is crucial for trustworthiness.<br/><br/>- Government collaboration with academia and private sectors is important for AI accountability.<br/>- Multi-disciplinary discussions should develop best documentation practices.<br/>- The government should make examples of documentation practices publicly available.<br/>- Ongoing support for a centralized repository can promote best practice documentation.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-1368" target=_blank>NTIA-2023-0005-1368</a> </h2>
<div >
<h3>online comments </h3>
- WITNESS is an international human rights organization that uses video and technology to protect and defend rights.<br/>- Their Technology Threats and Opportunities Team focuses on emerging technologies and their impact on society's trust in audiovisual content.<br/>- They have been researching the impact of artificial intelligence (AI) on discerning the truth and have consulted with various stakeholders.<br/>- They have identified concerns about deepfakes, synthetic media, and generative AI in the information ecosystem.<br/>- They have developed guidelines and recommendations for policy makers, technology companies, regulators, and other stakeholders.<br/>- This submission specifically focuses on AI accountability mechanisms and how they can inform people about the operation and compliance of AI tools, particularly in relation to synthetic videos, images, and audio.<br/>- The document is based on WITNESS' three decades of experience in creating trustworthy photo and video for human rights advocacy, protecting against content misuse, and challenging misinformation.
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-1368/attachment_1.pdf' download>attached document</a></h3>
- The content discusses the need for an AI accountability policy and suggests that it should be open for public comment.<br/>- The policy is proposed to be implemented by the National Telecommunications and Information Administration (NTIA).<br/>- The content emphasizes the importance of accountability in AI technology and the need for clear guidelines and regulations.<br/>- WITNESS, an international human rights organization, is mentioned as the source of the content.<br/>- The organization's mission is to help people use video and technology to document and expose human rights abuses.<br/>- They provide training and support to activists, journalists, and citizens in using video as a tool for advocacy.<br/>- WITNESS works with local partners to create and distribute videos that raise awareness and drive change.<br/>- The content focuses on engaging early with emerging technologies and staying ahead of the curve.<br/>- It highlights the importance of being aware of the potential benefits and risks associated with emerging technologies.<br/>- The content discusses the impact of synthetic media, deepfakes, and generative AI on society.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-1426" target=_blank>NTIA-2023-0005-1426</a> </h2>
<div >
<h3>online comments </h3>
- Hugging Face commends the NTIA Task Force on its work on AI accountability<br/>- Hugging Face is an open platform for AI systems<br/>- Hugging Face recommends focusing on transparency and data and algorithm subject rights for AI accountability<br/>- Hugging Face supports involving more stakeholders in shaping and critiquing AI technology<br/>- Hugging Face provides resources and tooling to lower the barrier for all backgrounds to contribute to AI.
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-1426/attachment_1.pdf' download>attached document</a></h3>
- Hugging Face commends the NTIA Task Force for their work on AI accountability and provides comments based on their experience as an open platform for AI systems.<br/>- AI accountability mechanisms such as certifications, audits, and assessments are important to ensure the safety, security, and well-being of users.<br/>- New accountability mechanisms should focus on verifying functionality, mitigating risks of discrimination, and providing basic security guarantees to users.<br/>- Transparency and sharing of results and documentation are important for accountability mechanisms to promote good practice and allow for diverse contributions and informed choices.<br/>- Accountability mechanisms for generative AI tools should focus on transparency, documentation, and external scrutiny to address biases and potential harms.<br/>- Accountability mechanisms should leverage inputs from various stakeholders and consider the needs of nonprofit actors, academic researchers, and small and medium enterprises.<br/>- Accountability efforts in AI systems should be distributed across the value chain, as most harms come from decisions made at various levels of development.<br/>- Strong standards for documentation and disclosure of data sources and processing are necessary for informed decision-making and accountability.<br/>- AI audits or assessments should take place at different stages of design, development, and deployment to provide meaningful accountability.<br/>- The accountability process should address data quality and data voids in different scenarios, such as the lack of historical data for newly deployed tools or limited data access for privacy and security reasons.<br/>- Lack of information shared about AI systems and lack of legal protections for novel AI impacts are significant barriers to effective AI accountability in the private sector.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-1349" target=_blank>NTIA-2023-0005-1349</a> </h2>
<div >
<h3>online comments </h3>
See attached file(s)
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-1349/attachment_1.pdf' download>attached document</a></h3>
- The National Telecommunications and Information Administration (NTIA) is seeking input on AI accountability policies, including transparency, explainability, fairness, and safety.<br/>- The Center for Responsible AI at New York University (NYU R/AI) conducts research, collaborates with government agencies, and advocates for responsible AI practices.<br/>- NYU R/AI offers educational initiatives, including courses and comic book series, to promote responsible AI literacy.<br/>- AI accountability mechanisms, such as certifications and audits, are important for ensuring responsible design and use of AI systems.<br/>- Lack of federal data protection laws and responsible AI education hinder effective AI accountability in the private sector.<br/>- Documentation and records, as well as standardized reporting, are crucial for supporting AI accountability.<br/>- Government policy should fund initiatives to advance a strong AI accountability ecosystem and support AI audits and assessments.<br/>- Responsible AI literacy, accountability-by-design principles, and strong government policies are strategies to overcome barriers to effective AI accountability.<br/>- Julia Stoyanovich, a researcher at NYU, has published numerous papers on AI accountability, fairness, and transparency.<br/>- The publications cover topics such as accuracy-explainability trade-offs, interventions to reduce inequality, responsible data management, bias and fairness in AI hiring, and more.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-1339" target=_blank>NTIA-2023-0005-1339</a> </h2>
<div >
<h3>online comments </h3>
Attached please find the response of The Institute for Workplace Equality to NTIA's AI Accountability Policy Request for Comment.
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-1339/attachment_1.pdf' download>attached document</a></h3>
- The content discusses the use of the Federal Rulemaking Portal for electronic document submission.<br/>- Ms. Stephanie Weiner is the Acting Chief Counsel of the National Telecommunications and Information Administration (NTIA).<br/>- The Institute for Workplace Equality has submitted comments in response to NTIA's AI Accountability Policy Request for Comment.<br/>- The comments address workplace equality in the context of AI accountability.<br/>- The Institute for Workplace Equality's comments are a response to NTIA's request for public input on the AI accountability policy.<br/>- The Institute for Workplace Equality is an organization focused on promoting workplace equality.<br/>- The organization works with companies to develop and implement diversity and inclusion strategies.<br/>- The Institute for Workplace Equality offers resources, education, and support to employers.<br/>- The Institute is a national, non-profit employer association based in Washington, D.C.<br/>- The organization educates federal contractors about their affirmative action and equal employment opportunity responsibilities.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-1381" target=_blank>NTIA-2023-0005-1381</a> </h2>
<div >
<h3>online comments </h3>
- DLA Piper's global AI and Data Analytics Practice (DLAI) has responded to NTIA's AI Accountability Policy Request for Comment.<br/>- DLAI's response consists of 26 pages of targeted inputs on important questions related to AI accountability.<br/>- The inputs cover various aspects of AI accountability throughout the entire AI lifecycle.<br/>- The purpose of the response is to help inform policies related to the development of AI audits, assessments, certifications, and other mechanisms to earn trust in AI systems.
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-1381/attachment_1.pdf' download>attached document</a></h3>
- Lack of transparency and data bias in AI systems hinder accountability and perpetuate discrimination.<br/>- Limited regulation and standards in the private sector make it difficult to hold AI systems accountable.<br/>- Companies may resist oversight measures due to concerns about revealing competitive advantage and protecting intellectual property.<br/>- Compliance fatigue and the challenges of keeping up with changing regulations pose accountability challenges.<br/>- Burdensome accountability processes require time, resources, and investments.<br/>- Lack of consensus standards in audit frameworks leads to subjective and inconsistent assessments.<br/>- Fragmented compliance landscape and varying laws and regulations make accountability challenging.<br/>- Implementing strong privacy controls in AI systems is challenging, contributing to public distrust.<br/>- Lack of expectations and standards for audits makes it difficult to develop a consistent process.<br/>- The cost of AI audits and assessments varies depending on complexity and scope.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-1391" target=_blank>NTIA-2023-0005-1391</a> </h2>
<div >
<h3>online comments </h3>
See attached file(s)
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-1391/attachment_1.pdf' download>attached document</a></h3>
- The National Telecommunications and Information Administration issued a notice on 04/13/2023, but the content is not provided.<br/>- The notice was authored by Kassandra Popper, a software developer, but the content is not provided.<br/>- The notice is related to a guidance document of the RFC and is dated 06/12/2023.<br/>- The content of the notice is divided into sections, each titled with the question number from the guidance document.<br/>- AI accountability mechanisms should focus on ensuring AI products function as advertised and meet industry and market norms.<br/>- Internal and external audits are useful for product quality assurance and investigating major problems.<br/>- AI audits or assessments can be integrated into accountability mechanisms for other goals such as human rights, privacy protection, security, and diversity.<br/>- AI accountability practices can be a competitive advantage and should be designed well.<br/>- Certifications, audits, and assessments promote trust for external stakeholders and should not overly concern internal processes.<br/>- Tradeoffs exist between AI system effectiveness and limiting outputs within certain boundaries.<br/>- AI accountability mechanisms should incentivize distributing AI benefits widely and efficiently to counter systemic risks.<br/>- Over-regulation of the AI industry can impede progress in AI R&D and delay the development of trustworthy AI systems.<br/>- AI accountability efforts should focus on data collection and distribution to customers.<br/>- Accountability mechanisms should focus on the point of final application rather than on frontier models.<br/>- AI accountability should be mandatory for applications with a significant risk of harm.<br/>- AI systems should not require quality assurance certifications unless they involve higher risk.<br/>- Lack of a federal law focused on AI systems is not a barrier to effective AI accountability.<br/>- Governments have legal and regulatory tools to address the impacts and accountability of AI software systems.<br/>- Leaving the specification of AI accountability mechanisms to the most granular governmental level is preferable for customization.<br/>- A new federal law may not be required for effective AI accountability.<br/>- Accountability mechanisms should not burden new entrants and should minimize friction in publishing AI research artifacts and new products.<br/>- AI accountability policy should be sectoral, tailored to the specific requirements of each sector.<br/>- The focus of AI accountability regulation should be on inputs to validation, particularly on data needed to ensure that a product is functioning as advertised and suitable for its intended purpose.<br/>- Increased access to AI systems for researchers or auditors should not be required, unless necessary to investigate a demonstrated failure of an AI system that has caused serious or permanent harm during normal operation.<br/>- Mandating accounting measures should only be done if there is a significant risk of serious or permanent harm resulting from the normal operation of the AI system.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-1314" target=_blank>NTIA-2023-0005-1314</a> </h2>
<div >
<h3>online comments </h3>
See attached file(s)
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-1314/attachment_1.pdf' download>attached document</a></h3>
- The Integrity Institute has submitted comments to the NTIA on AI accountability policies.<br/>- They have expertise in addressing harms on social internet platforms and believe their knowledge can contribute to responsible AI development.<br/>- The comments likely provide recommendations and suggestions for improving AI accountability policies.<br/>- The Institute supports accountable AI policies as a starting point and sees parallels between the rush to market of social media platforms and the need for safety and transparency in AI.<br/>- They have also provided feedback on the EU AI Act and the potential of generative AI in integrity work.<br/>- The comments provided by the Integrity Institute are in response to specific questions posed by the NTIA.<br/>- They aim to contribute to the development of AI accountability policies and provide valuable insights and recommendations.<br/>- AI accountability mechanisms such as certifications, audits, and assessments contribute to transparency and explainability of AI systems.<br/>- Accountability mechanisms should cover the harms and risks of AI systems, including exposure to illegal and harmful content, bias and exclusion, and violation of privacy, security, and human rights.<br/>- AI accountability mechanisms should adopt principles, benchmarks, and legal standards associated with human rights, privacy protection, security, and diversity, equity, inclusion, and access.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-1283" target=_blank>NTIA-2023-0005-1283</a> </h2>
<div >
<h3>online comments </h3>
Please find CIPL's comments attached.
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-1283/attachment_1.pdf' download>attached document</a></h3>
- The Centre for Information Policy Leadership (CIPL) supports federal data privacy legislation in the United States and believes it is foundational to effective AI regulation.<br/>- CIPL's Accountability Framework can be used to promote organizational accountability in the context of AI, covering areas such as leadership, risk assessment, transparency, and response and enforcement.<br/>- Certifications, audits, and assessments are essential in building trust and demonstrating compliance with AI accountability measures.<br/>- Internal and external audits can be conducted to identify and mitigate risks, and provide neutral views on ethical and compliance issues.<br/>- AI accountability practices can have a meaningful impact even without legal standards, and the role of courts, legislatures, and rulemaking bodies is important in setting guidance and standards.<br/>- A multidisciplinary approach involving various stakeholders is necessary to address trade-offs among different AI accountability goals.<br/>- AI accountability measures should cover topics such as discrimination, privacy protection, security, and diversity, equity, inclusion, and access.<br/>- Certifications, audits, and assessments promote trust for external stakeholders and drive internal process changes.<br/>- AI accountability measures should be conducted by a single team or instrument to ensure a balanced approach.<br/>- Existing accountability frameworks and resources in cybersecurity, privacy, and finance can provide useful models for AI accountability.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-1281" target=_blank>NTIA-2023-0005-1281</a> </h2>
<div >
<h3>online comments </h3>
Please see the attached comments from Lumeris.
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-1281/attachment_1.pdf' download>attached document</a></h3>
- Lumeris, a leading healthcare technology and insurance provider, supports the use of AI technologies in healthcare and appreciates the NTIA's dedication to ensuring their safe and effective use.<br/>- Lumeris recommends that AI accountability assessments focus on accuracy, compliance with regulations, and ethical considerations.<br/>- They emphasize the importance of AI systems not contributing to harmful discrimination or misinformation.<br/>- Lumeris believes that existing regulations, such as HIPAA, address privacy concerns in the healthcare industry.<br/>- They argue against legislation requiring human alternatives to AI systems, citing examples where AI models outperformed physicians.<br/>- Lumeris emphasizes the need for balancing access to AI systems with safeguards and redress for individuals affected by their outputs.<br/>- Validation processes for building AI systems should involve consultation with clinicians.<br/>- Existing requirements and standards in healthcare provide guidance for trustworthy AI.<br/>- Some accountability mechanisms may hinder the development of trustworthy AI and impact the competitiveness of U.S. developers.<br/>- Government policy should play a role in the AI accountability ecosystem, and policies and regulations can be sectoral or horizontal.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-1447" target=_blank>NTIA-2023-0005-1447</a> </h2>
<div >
<h3>online comments </h3>
See Attached
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-1447/attachment_1.pdf' download>attached document</a></h3>
- The focus of this topic is on accountability mechanisms in relation to the development of trustworthy AI.<br/>- There is a concern that certain accountability mechanisms may not contribute to the advancement of trustworthy AI and could potentially hinder its development.<br/>- The question also raises the issue of accountability mechanisms that may have a negative impact on AI innovation and the competitiveness of developers in the United States.<br/>- Accountability mechanisms can unintentionally hinder innovation and hinder smaller AI developers' competitiveness.<br/>- Strict regulations like the GDPR can place a disproportionate burden on small startups and independent developers.<br/>- The costs associated with compliance, including legal, operational, and technological expenses, can impede progress and financial stability.<br/>- Stringent accountability measures can discourage risk-taking and innovation in the development of AI technologies.<br/>- Developers may opt for safer and more conventional approaches to avoid potential lawsuits or fines.<br/>- This cautious approach can limit the growth and development of AI technologies.<br/>- Compliance with regulations requires significant time and resources.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-1264" target=_blank>NTIA-2023-0005-1264</a> </h2>
<div >
<h3>online comments </h3>
Please find attached comments of CTIA.
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-1264/attachment_1.pdf' download>attached document</a></h3>
- CTIA is an organization that focuses on the accountability of artificial intelligence (AI) technologies.<br/>- They aim to promote transparency, fairness, and ethical considerations in AI systems.<br/>- CTIA is committed to providing valuable insights and information for the National Telecommunications and Information Administration's (NTIA) AI Accountability Report.<br/>- They recognize the importance of responsible AI development and deployment.<br/>- CTIA will collaborate with NTIA to ensure the report addresses the ethical and societal implications of AI.<br/>- The organization is located in Washington, DC and can be contacted at 202-736-3200.<br/>- More information about CTIA can be found on their website at www.ctia.org.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-1207" target=_blank>NTIA-2023-0005-1207</a> </h2>
<div >
<h3>online comments </h3>
See attached PDF.
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-1207/attachment_1.pdf' download>attached document</a></h3>
- Travis Hall is seeking comments on AI accountability policy, specifically on the role of governments in AI regulation.<br/>- Contact information for Travis Hall is provided as 1401 Constitution Avenue NW, Room 4725, Washington, DC 20230.<br/>- The request is titled "Software implementing government law or policy is a rule and should go through the rulemaking process."<br/>- The request asks about the use of AI systems and expectations for audits and assessments.<br/>- It also questions whether accountability practices for AI systems in the public sector should differ from those in the private sector.<br/>- The request inquires about the contribution of government procurement practices to a productive AI accountability ecosystem.<br/>- The content mentions a specific rule, "Restrictions Applicable to Flights Carrying Persons Who Have Recently Traveled From or Were Otherwise Present Within the People's Republic of China, 85 Fed. Reg. 6044 (Feb. 4, 2020)" regarding travel restrictions in response to COVID-19.<br/>- The content highlights that the rulemaking process is well established and can accommodate speedy action when needed.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-1190" target=_blank>NTIA-2023-0005-1190</a> </h2>
<div >
<h3>online comments </h3>
- Knowledge Ecology International (KEI) objects to provisions in US trade agreements that restrict the transparency of software code or algorithms.<br/>- KEI believes that policy makers should require transparency in certain areas and topics related to algorithms and AI services.<br/>- Prohibiting government intervention in mandating transparency is a mistake, as there may be a compelling case for intervention to mitigate harm or promote welfare-enhancing policies.<br/>- The attached PDF file provides more details on KEI's objections and arguments.
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-1190/attachment_1.pdf' download>attached document</a></h3>
- KEI is a non-profit organization based in Washington, DC, with an office in Geneva, Switzerland.<br/>- They are commenting on the topic of AI audits and assessments in response to a notice by the National Telecommunications and Information Administration (NTIA).<br/>- KEI expresses concerns over trade agreement provisions that limit the transparency of source code and algorithms.<br/>- The United States Trade Representative (USTR) has advocated for these provisions in several plurilateral trade agreements.<br/>- KEI has seen these proposals in the Trans Pacific Partnership (TPP), the Trade in Services Agreement (TiSA), and the Agreement between the United States, Mexico, and Canada (USMCA).<br/>- They believe that these provisions are too restrictive and lack sufficient exceptions, even for software licensed under obligations to make code public.<br/>- KEI argues that transparency of computer code and algorithms should be an option in national legislation and a subject of global norms.<br/>- They mention the European Commission's creation of a European Centre for Algorithm Transparency as an example.<br/>- Many groups, including those working on AI accountability, right to repair, and open standards, have called for transparency measures.<br/>- KEI believes that trade agreements should not broadly prohibit government mandates for transparency in areas where there is a compelling case for intervention.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-1152" target=_blank>NTIA-2023-0005-1152</a> </h2>
<div >
<h3>online comments </h3>
See attached file(s)
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-1152/attachment_1.pdf' download>attached document</a></h3>
- The Computing Community Consortium (CCC) has responded to the Request for Comment (RFC) on AI Accountability Policy.<br/>- The CCC's response provides insights and recommendations on various aspects of AI accountability.<br/>- The authors of the response include experts from various universities and organizations.<br/>- The response emphasizes the need to recognize, control, and mitigate the negative impacts of AI systems.<br/>- The complexity and diversity of AI systems make it challenging to understand and hold them accountable.<br/>- The response suggests proposing mechanisms for holding AI systems accountable and asks important questions about auditing and accountability.<br/>- Different levels of audit are necessary to ensure comprehensive understanding of AI accountability.<br/>- Retraining AI systems and continuous updates are important for their performance and effectiveness.<br/>- Certifying complex systems and integrating AI-supported functionality is a challenging task.<br/>- The response highlights the importance of respecting the principles of Respect for Persons, Beneficence, and Justice in AI technology.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-1218" target=_blank>NTIA-2023-0005-1218</a> </h2>
<div >
<h3>online comments </h3>
See attached file(s)
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-1218/attachment_1.pdf' download>attached document</a></h3>
- Chegg, Inc. has submitted comments on the NTIA's request for comment on artificial intelligence system accountability measures and policies.<br/>- The company emphasizes the need for transparency in AI systems, including clear explanations of how decisions are made and the data used.<br/>- Chegg supports the development of standards and best practices for AI accountability, but also highlights the importance of flexibility to accommodate different industries and use cases.<br/>- The company is interested in contributing to the development of policies that can enhance trust in AI and ensure responsible use of AI systems.<br/>- Chegg is a global education technology company that provides digital tools to help students access affordable educational services.<br/>- They have over 8 million student subscribers worldwide and operate in over 150 countries.<br/>- Chegg extensively uses AI in their platform to improve learning outcomes and provide personalized learning experiences.<br/>- The company recognizes the importance of audits, assessments, certifications, and other mechanisms in building trust in AI systems.<br/>- They emphasize the need for transparency, explainability, and accountability in the use of AI tools.<br/>- Chegg supports the idea of a standardized and cohesive approach to AI oversight and encourages the NTIA to consider models and best practices from other regulatory frameworks.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-1210" target=_blank>NTIA-2023-0005-1210</a> </h2>
<div >
<h3>online comments </h3>
See attached file(s)
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-1210/attachment_1.pdf' download>attached document</a></h3>
- Unlearn.AI is submitting comments to the NTIA AI Accountability Request for Comment, with a focus on advancing AI in medicine and eliminating trial and error in clinical trials.<br/>- They believe accountability mechanisms should be enforced by the specific governmental agency that regulates the context of AI use, and certifications, audits, and assessments can promote trust and improve internal processes.<br/>- Responsible governmental agencies should create policies to accommodate novel AI/ML applications, and the FDA is taking steps to engage stakeholders in this domain.<br/>- The emphasis on accountability mechanisms should be based on risk and use case, with definitions specific to each sector and consideration of intellectual property and context-of-use.<br/>- Risk-based frameworks for AI should be established by regulatory agencies in each sector, and government policy should be sectoral to achieve uniformity.<br/>- The most significant barriers to AI accountability in the private sector are proprietary technology and IP protection.<br/>- Uniformity of AI accountability requirements and practices is important within sectors and potentially across global jurisdictions, and harmonization or interoperability can be sufficient for achieving this.<br/>- Applying accountability requirements uniformly across all sectors in the US could hinder innovation.<br/>- Jess Ross is the Senior Government Affairs Lead at Unlearn.AI.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0298" target=_blank>NTIA-2023-0005-0298</a> </h2>
<div >
<h3>online comments </h3>
- The user's problem is not with AI technology itself, but with how it is being used to create competition against traditional artists without their consent or compensation.<br/>- AI programs are collecting freely from portfolios without permission, resulting in the imitation of traditional artists' work without credit or compensation.<br/>- Arguments defending AI art, such as it being "transformative" or comparable to human learning, are not valid according to the user.<br/>- The user believes that even small amounts of data sampled from artists' work should not be used without their consent.<br/>- The user suggests that art programs should be restricted to sampling work in the public domain, fairly purchased, or volunteered from willing artists.<br/>- The user emphasizes the importance of considering and respecting the rights of real artists in the development of new technologies.<br/>- Traditional artists pour their lives into their work and deserve respect and compensation for their talent.<br/>- Artists should have a say in how their art is proliferated and used, as it is often a business for them.<br/>- The user calls for responsible use of AI technology in the art field.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0299" target=_blank>NTIA-2023-0005-0299</a> </h2>
<div >
<h3>online comments </h3>
- AI art and AI-made material are considered unethical, unsafe, and untrustworthy as a medium.<br/>- AI takes the hard work of artists and others without permission or consent, using it to create products without their input.<br/>- This undermines artist rights and control over their own work, which is already a struggle for many artists.<br/>- Allowing AI to control costs without regulation can have serious negative impacts on people's livelihoods and may lead to job losses in the long run.<br/>- Trusting AI art is a terrible idea as it actively appropriates the work of individuals without their consent, profiting from something they had no involvement in.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0291" target=_blank>NTIA-2023-0005-0291</a> </h2>
<div >
<h3>online comments </h3>
- AI is a versatile tool with potential for harm<br/>- AI learning models use both free and privatized content<br/>- Using privatized content without consent is a form of theft from creators<br/>- AI-generated artwork should be legally required to disclose its AI origin<br/>- Failure to disclose AI-generated content should have large penalties<br/>- AI-generated content can be used to manipulate political scenarios<br/>- The use of AI as a tool needs to be curtailed promptly to prevent harm.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0292" target=_blank>NTIA-2023-0005-0292</a> </h2>
<div >
<h3>online comments </h3>
- Training data is crucial for the quality and versatility of generative AI algorithms.<br/>- These algorithms are illegally using copyrighted content without consent to generate their own content.<br/>- The algorithms lack understanding of lighting, form, and 3D space, and rely on statistical occurrence in training data.<br/>- Generating realistic deepfakes requires massive amounts of training data.<br/>- Generative AI apps likely scrape millions of pieces of content to produce accurate results.<br/>- This exploitation of content creators can lead to job loss in creative industries.<br/>- Generative AI can also be used for harmful purposes such as creating fake nude pictures, child pornography, and spreading misinformation.<br/>- Ethical and legal use of generative AI requires consented data.<br/>- Regulation is needed to prevent unethical, illegal, and dangerous use of AI.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0294" target=_blank>NTIA-2023-0005-0294</a> </h2>
<div >
<h3>online comments </h3>
- AI writing and art systems are currently not ethical, safe, or trustworthy.<br/>- The spread of disinformation is a major concern with the use of AI.<br/>- AI systems like ChatGPT can provide incorrect or harmful information due to their reliance on sources that may contain misinformation or propaganda.<br/>- AI art/image systems like Midjourney can generate realistic pictures that can be used to spread misinformation.<br/>- The lack of regulation for AI could lead to the easy spread of false information and the loss of context for AI-generated content.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0295" target=_blank>NTIA-2023-0005-0295</a> </h2>
<div >
<h3>online comments </h3>
- AI is considered unsafe and unethical for creators<br/>- AI has been known to use content without the consent of human creators to teach itself<br/>- AI has the potential to steal good work from people<br/>- The use of AI has already impacted multiple creative industries<br/>- The Writers Guild of America (WGA) is striking due to unfair pay and the increasing use of AI<br/>- Large corporations could easily replace humans with AI, leading to increased profits for them<br/>- The idea of being replaced by a non-sentient machine is unsettling for many creators.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0300" target=_blank>NTIA-2023-0005-0300</a> </h2>
<div >
<h3>online comments </h3>
- AI image creation currently exploits artists and their intellectual property without their consent.<br/>- The technology relies on the work of talented creators, without whom AI would be unable to produce anything.<br/>- Artists are protesting proposals that would allow studios to use AI-generated writing and have writers revise it for reduced pay.<br/>- AI-generated writing is based on the work of writers, essentially stealing their art and demanding they accept less for their work.<br/>- Artists question why they should support a technology that profits from their work without compensation or credit.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0307" target=_blank>NTIA-2023-0005-0307</a> </h2>
<div >
<h3>online comments </h3>
- Artists are facing issues regarding the use of AI software in the world of art.<br/>- AI has been used in various fields, including video games and search engines.<br/>- There are programs that use AI to generate images based on image data and word prompts.<br/>- Many of the images fed into these AI programs are stolen from artists.<br/>- The images created by AI software are not considered art because they lack human creativity and imagination.<br/>- Artists are upset because their work is being stolen and used without their permission or credit.<br/>- The unethical use of AI art programs is taking jobs and earning money from artists.<br/>- Laws should be put in place to protect artists from the malicious use of AI "art" programs.<br/>- The use of illegally obtained art in AI-generated images should be punishable by law enforcement.<br/>- AI art programs are harmful to artists' livelihoods and action should be taken against them.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0308" target=_blank>NTIA-2023-0005-0308</a> </h2>
<div >
<h3>online comments </h3>
I do not believe that AI as it stands in the hands of Silicon Valley and its obsessive followers will bring anything good into this world.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0310" target=_blank>NTIA-2023-0005-0310</a> </h2>
<div >
<h3>online comments </h3>
The U.S. government should protect the livelihood of the country's artists hy restricting general usage for AI image/text generators.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0319" target=_blank>NTIA-2023-0005-0319</a> </h2>
<div >
<h3>online comments </h3>
- The user has a strong interest in Artificial Intelligence and has been studying it for their whole life.<br/>- They are pursuing a computer science degree with a concentration in using AI in online security.<br/>- The user believes that tech CEOs and financers do not understand the technology and its implications.<br/>- They argue that AI software stores data from art and writing without permission, and the people promoting it do not care about the harm it causes.<br/>- The user believes that technology should make our lives easier and enable us to pursue art, music, and writing freely.<br/>- They criticize the use of scraped art pieces in datasets without the original artists' permission, which is a copyright violation.<br/>- The user suggests that datasets should only contain Royalty Free/Creative Commons art or commissioned and paid art.<br/>- They argue that if AI is to exist, it must work in conjunction with artists and pay them fairly.<br/>- The user believes that the use of a dataset should pay the artists, not the dataset hosts or software owners.<br/>- They state that if the technology cannot accommodate fair compensation for artists, it should not be used until it can.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0321" target=_blank>NTIA-2023-0005-0321</a> </h2>
<div >
<h3>online comments </h3>
AI is taking away to many jobs, before long half of the jobs will be taken over by AI, where does that leave the people. This stiff has to be regulated before everyone is out of work.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0323" target=_blank>NTIA-2023-0005-0323</a> </h2>
<div >
<h3>online comments </h3>
- Government should establish an independent committee to regulate AI creation and usage<br/>- Committee should have powers similar to the FDA to evaluate accountability of AI models<br/>- Regulations for evaluating AI models should be based on expert research and funded by the government<br/>- Committee should have subcommittees focusing on specific sectors like research, education, business, public awareness, and certification<br/>- Brazil's national AI policy provides a good example with guidelines and actions across six pillars<br/>- China also has a similar policy targeting ethics and social responsibility in each sector
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0327" target=_blank>NTIA-2023-0005-0327</a> </h2>
<div >
<h3>online comments </h3>
- User is concerned about the lack of AI regulation in the US<br/>- User is both a consumer and a professional audiobook narrator and artist<br/>- Tech companies have harvested large amounts of data without permission, including copyrighted content<br/>- User believes the current tech being offered is a Trojan horse to train untested, unethical, and unsafe AI<br/>- User urges for strict regulation of AI technology
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0334" target=_blank>NTIA-2023-0005-0334</a> </h2>
<div >
<h3>online comments </h3>
- Concerns with AI are two-fold: provenance of text/images used and fair compensation for creators<br/>- Provenance is important to prevent theft of work and allow creators to withdraw their work if they don't consent to its use<br/>- Media companies may use AI to justify paying creators less, putting them out of business<br/>- AI-assisted writing is less labor intensive, but revising and polishing still require work<br/>- Creative workers deserve fair compensation and AI could make their work untenable<br/>- Currently, there's no way to tell how a piece of creative work was created, disclosure should be required if AI was used<br/>- Copyright law for AI text needs clarification to avoid potential litigation.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0097" target=_blank>NTIA-2023-0005-0097</a> </h2>
<div >
<h3>online comments </h3>
AI should surely be regulated in some way.  But I'm afraid I don't specifically know how.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0104" target=_blank>NTIA-2023-0005-0104</a> </h2>
<div >
<h3>online comments </h3>
In the development of AI, equality should not be considered extra but rather an essential component of the minimum standard for evaluation. Additionally, any resources allocated towards ensuring the legality, safety, effectiveness, and non-discriminatory nature of artificial intelligence are not a tradeoff but a worthwhile investment.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0130" target=_blank>NTIA-2023-0005-0130</a> </h2>
<div >
<h3>online comments </h3>
- AI products can be ethical if the database consists of components willingly provided by rightful owners<br/>- Copyrighted works should not be used for profit by third parties<br/>- AI creations should be automatically watermarked to indicate their use of algorithms<br/>- The database should be switched to stock files provided by creatives and owners should be rewarded<br/>- Websites should default to an opt-out option for adding content to AI databases, with opt-in being voluntary<br/>- Websites should clearly and prominently inform users about their data usage policies
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0134" target=_blank>NTIA-2023-0005-0134</a> </h2>
<div >
<h3>online comments </h3>
- AI is derived from the information it is given<br/>- AI uses the work of many artists without permission or consent<br/>- AI broadcasts art without giving credit to the human creators<br/>- This negatively impacts working artists<br/>- AI is not necessary for the field of entertainment<br/>- AI takes the "human" out of art<br/>- Artists and their work deserve legal protection and compensation
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0114" target=_blank>NTIA-2023-0005-0114</a> </h2>
<div >
<h3>online comments </h3>
AI is dangerous and will take away jobs in the future. We will end up serving the AI instead of the other way around, and nobody will benefit from this in the long run. Make AI accountable and limit what it can do so it can remain a useful tool that's not taking any jobs.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0118" target=_blank>NTIA-2023-0005-0118</a> </h2>
<div >
<h3>online comments </h3>
- AI is currently considered untrustworthy due to concerns about stolen data and copyright infringement.<br/>- Organizations and individuals developing AI are using data without permission or regard for copyright.<br/>- To ensure fair and equitable use of AI, data sets should require opt-in consent rather than opt-out.<br/>- A verifiable and traceable system is needed to track the datasets and sources used by AI in creating content.<br/>- Strong regulations are necessary to prevent widespread copyright breaches in the field of AI/ML/LLM.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0122" target=_blank>NTIA-2023-0005-0122</a> </h2>
<div >
<h3>online comments </h3>
- AI poses dangers to both jobs and the fabric of society, as it can be used to fabricate information, impersonate people, and create realistic depictions of child exploitation.<br/>- Copyright law aims to protect the rights of authors to exploit their creations and prevent them from competing against themselves or derivatives of their work.<br/>- In the digital realm, copyright also extends to the binary sequence that represents an authored creation, even if it has been altered through computer instructions like file compression.<br/>- AI models are derivative products of their training data, and each individual piece of data is nonfungible and contributes to the final model. Removing data requires retraining the model from scratch.<br/>- The Copyright Office's previous stance that human work on an AI-generated product may claim copyright over the final product should be rescinded because it usurps the market of the original product and is a derivative of it. Adding additional steps of derivation does not escape this demand.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0136" target=_blank>NTIA-2023-0005-0136</a> </h2>
<div >
<h3>online comments </h3>
Generative AI, especially in it's current form, is predicated on taking the work of countless others and just turning it into a slightly different product. It is important to protect creators and other workers from Generative AI's stealing of their hard-work.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0143" target=_blank>NTIA-2023-0005-0143</a> </h2>
<div >
<h3>online comments </h3>
- Unethical practices are prevalent in the field of AI, where people take others' work without consent and rearrange it for their own benefit.<br/>- This behavior is considered theft, as people feel entitled to others' work without permission.<br/>- AI should have strict restrictions in place to prevent these unethical practices from continuing.<br/>- The current trajectory of AI technology may lead to a situation where it replaces hardworking individuals, resulting in a negative outcome.<br/>- The concept of "work smarter, not harder" should only apply when the results are comparable to those achieved through hard work, not when generating random and inappropriate content.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0176" target=_blank>NTIA-2023-0005-0176</a> </h2>
<div >
<h3>online comments </h3>
- The term "AI Art" is a misnomer, as it is more accurately described as machine gathered learning (ML).<br/>- Programs like Midjourney, Stable Diffusion, and Dall-E sift through thousands of original artworks without consent to generate images based on user prompts.<br/>- Some companies involved in this trend are valued at billions of dollars, while others are valued in the millions.<br/>- The lack of regulation in this new trend allows for the exploitation of artists without credit or pay.<br/>- The use of AI art as a cheap alternative to traditional illustration or animation is detrimental to career artists.<br/>- Many artists in fields such as novel covers, board games, card games, video games, animation, and concept art have lost their jobs due to AI art.<br/>- AI art does not fit the definition of art as it appropriates existing works without creative skill or imagination.<br/>- Regulation is necessary to address the negative impact of AI art on artists and the potential loss of jobs in other industries.<br/>- The widespread adoption of AI could lead to an economic crisis if many people become unemployed.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0195" target=_blank>NTIA-2023-0005-0195</a> </h2>
<div >
<h3>online comments </h3>
- AI in its current state is dangerous for various reasons<br/>- From a capitalistic standpoint, AI is unregulated and profits off stolen work without compensation<br/>- This poses a problem for independent businesses and major corporations with copyright concerns<br/>- From a humanistic standpoint, AI enables identity theft, fraud, and libel<br/>- It raises questions about relying on AI-generated content for important purposes like medical dissertations or news outlets<br/>- There is a risk of AI being used for generating pornography of minors<br/>- While AI has benefits, regulations and laws are necessary to address copyright, impersonation, and criminal intent.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0279" target=_blank>NTIA-2023-0005-0279</a> </h2>
<div >
<h3>online comments </h3>
Ai is stealing from hard working people, hope this helps !!!
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0289" target=_blank>NTIA-2023-0005-0289</a> </h2>
<div >
<h3>online comments </h3>
- The user is Robert Cruz, a citizen of Riverside County, California, who regularly votes for California's 25th congressional district.<br/>- Robert is not college educated and works as an independent contractor in the creative sector.<br/>- He believes that regulating AI is important, particularly in terms of ethics.<br/>- He explains that Generative AI is an imitative digital scanner that creates "art" by assembling pixels from a dataset onto a new image.<br/>- This AI requires human artists to input prompts and contribute to its dataset.<br/>- Robert is concerned about the use of Generative AI to create convincing deepfake imagery that can implicate people in criminal acts.<br/>- He mentions that far-right conservatives have already used Generative AI to create doctored images to promote hatred towards LGBTQ+ people.<br/>- He warns that this technology could potentially be used to sabotage a presidential campaign in the future.<br/>- Robert believes that the use of Generative AI in the creative field will lead to widespread job loss and poverty in the United States.<br/>- He emphasizes the need for strict ethics laws to prevent the circulation of harmful images created by AI.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0290" target=_blank>NTIA-2023-0005-0290</a> </h2>
<div >
<h3>online comments </h3>
- Artist expresses concern about security issues with AI in studios<br/>- Many companies require employees to sign NDA files, but AI databases draw on public resources<br/>- Artist worries that if AI is trained on NDA files, it may accidentally leak sensitive information<br/>- AI's unsecured database to draw references from is seen as a security leak<br/>- Artist mentions The Chinese Room experiment as a way to understand how AI works, comparing it to a person in a room pulling files without understanding nuance like slang.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0206" target=_blank>NTIA-2023-0005-0206</a> </h2>
<div >
<h3>online comments </h3>
- AI should be prohibited in policing due to the potential for false arrests and incarceration, particularly affecting people of color.<br/>- The use of AI technology to create falsified nude photos without consent is a significant violation and needs to be addressed.<br/>- The danger of AI being used for revenge porn makes it risky for individuals to have their faces online.<br/>- Copyright concerns arise from the use of artists' and writers' works without their consent to train AIs.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0228" target=_blank>NTIA-2023-0005-0228</a> </h2>
<div >
<h3>online comments </h3>
- AI-generated art often steals aspects of art made by human artists without permission or notification.<br/>- This stolen art is then sold or used without the original artist's consent.<br/>- Sometimes, the original artist is deceased and unable to submit a complaint.<br/>- Regulations and safeguards are needed to prevent AI from sampling and stealing from other artists.<br/>- Websites using AI generation methods should have simpler ways for artists to opt out and remove their art from the reference pool.<br/>- Inactive accounts should have their art removed after a period of inactivity to protect artists who have passed away.<br/>- Government intervention is necessary to protect the rights of artists and prevent the fading of art from the internet.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0316" target=_blank>NTIA-2023-0005-0316</a> </h2>
<div >
<h3>online comments </h3>
- AI has been used by major corporations to replace human workers in order to avoid paying them.<br/>- AI engineers have sometimes stolen the work of artists, writers, and translators to train AI, violating copyright laws.<br/>- AI has been used in facial recognition software and Tesla cars, but inherit biases from their creators, leading to harm and discrimination.<br/>- AI development needs oversight of ethics and diversity to handle biases and ensure different experiences are considered.<br/>- AI should be seen as a tool, but without accountability, people may lose faith in technology.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0246" target=_blank>NTIA-2023-0005-0246</a> </h2>
<div >
<h3>online comments </h3>
- The user expresses concern about the movement for AI to replace jobs without consent.<br/>- They mention the use of AI tools to steal original art without consequences.<br/>- The user believes that AI is being used in ways that harm small businesses.<br/>- They argue against AI making decisions for humans and replacing artists, writers, and creators.<br/>- The user criticizes the use of AI in government decisions and the disenfranchisement of people from various professions.<br/>- They suggest that AI should be used for labor that humans cannot do.<br/>- The user emphasizes the need to protect artists and writers affected by the misuse of AI programs.<br/>- They call for more research on the societal impact of AI before widespread implementation.<br/>- The user opposes the idea of AI writing movies, books, and articles.<br/>- They claim that most Americans do not want AI to take over.<br/>- The user believes that those in charge of large corporations want to use AI to replace employees instead of supporting them.<br/>- They argue that AI should replace hard work to give humans more time for art and other passions.<br/>- The user emphasizes the importance of protecting art, writers, and small businesses.<br/>- They urge for a realization that replacing things people love with robots will not make them happy.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0258" target=_blank>NTIA-2023-0005-0258</a> </h2>
<div >
<h3>online comments </h3>
- AI is being used to create art, music, literature, and other creative works without the consent or credit of artists.<br/>- Unregulated AI allows corporations to exploit artists for mass-produced, lower-quality content.<br/>- AI cannot replicate the artist's unique creative process.<br/>- The livelihood, careers, and creations of artists need to be protected from AI exploitation.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0271" target=_blank>NTIA-2023-0005-0271</a> </h2>
<div >
<h3>online comments </h3>
- Michael Schwarz, a key figure in a large tech company developing AI systems, acknowledges that AI will be used by bad actors and cause real damage.<br/>- Some AI researchers downplay concerns about AI harms and instead focus on potential benefits like curing cancer and solving world hunger, without definitive proof.<br/>- Current AI systems, such as Large Language Models, have already been abused, leading to intellectual property violations and exploitation.<br/>- Deepfake technology, which utilizes AI, has resulted in scams, blackmail, and erosion of trust in institutions.<br/>- Proponents of unmitigated AI development often dismiss concerns and claim that anyone could already do harm, ignoring the fact that they are exacerbating the situation.<br/>- From an economic standpoint, AI could lead to significant job losses, with estimates suggesting up to 80% of jobs could be affected.<br/>- The assumption that automation will create new jobs and allow people to live fulfilling lives lacks solutions and ignores the unreliable nature of AI systems.<br/>- AI integration could also enable corporations to outsource unethical and discriminatory practices to an automated system with plausible deniability.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0268" target=_blank>NTIA-2023-0005-0268</a> </h2>
<div >
<h3>online comments </h3>
- The user is an illustrator who shares their work online for free but still owns the rights to it.<br/>- They charge different rates for personal illustrations and those used for business purposes.<br/>- The user believes that AI neglects their right to own their intellectual property and strips them of rights without compensation or knowledge.<br/>- They argue that AI's open sourcing is harmful to anyone who shares their work online.<br/>- The user also expresses concerns about personal privacy and identity ownership, as AI interfaces are fed with pictures of people's children, family, and friends.<br/>- They hope their experience and fears about AI are taken into consideration.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0500" target=_blank>NTIA-2023-0005-0500</a> </h2>
<div >
<h3>online comments </h3>
- Concerns about the rapid evolution of technology and its impact on individuals financially and mentally<br/>- Calls for regulation and ethical oversight of Generative AI to prevent radical changes in creative industries and people's lives<br/>- Companies releasing AI technologies without ensuring safety, ethics, and consent, leading to negative consequences for original creators and owners<br/>- Examples of firings, artists struggling, voice actors fearing obsolescence, deepfakes causing distress, and writers strike<br/>- Serious issues like child pornography being produced using AI technologies<br/>- Urgent need for governing parties to take action and regulate this technology to prevent further harm<br/>- Demand for public input and control over data usage and protection of privacy rights<br/>- Presentation held to raise awareness about the dangers of Generative AI, with attached slides and sources for reference<br/>- Request for immediate action to address these concerns.
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-0500/attachment_1.pdf' download>attached document</a></h3>
- The content discusses the dangers of generative AI.<br/>- It mentions a specific link to a website called Unstable Diffusion (https://www.unstability.ai/).<br/>- The website likely provides more information on the topic of generative AI and its associated risks.<br/><br/>- The provided content is a tweet with a link to a discussion about the dangers of generative AI.<br/>- The tweet is from a user named @kingsevil0000.<br/>- The link leads to a thread or article discussing the topic further.<br/>- The dangers of generative AI are likely to be explored in the linked content.<br/><br/>- Generative AI poses significant dangers in the digital world<br/>- The proliferation of fake content online is a direct result of generative AI technology<br/>- The ability to create realistic and convincing fake images, videos, and text is a major concern<br/>- The widespread dissemination of fake content can lead to misinformation, manipulation, and harm<br/>- It is becoming increasingly difficult to distinguish between real and fake content online<br/>- The impact of generative AI on society and<br/><br/>- The content is about the dangers of generative AI.<br/>- It mentions a specific link, H.R.2395, which is related to the DEEP FAKES Accountability Act.<br/>- The DEEP FAKES Accountability Act is likely a legislative measure aimed at addressing the risks associated with deepfake technology.<br/>- The article or discussion likely highlights the potential negative consequences of generative AI and the need for accountability measures like the DEEP FAKES Accountability Act.<br/><br/>- The content discusses the dangers of generative AI.<br/>- It includes a link to a bill on the Congress website, specifically House Bill 2395 of the 117th Congress.<br/>- The bill likely addresses the regulation or control of generative AI technology.<br/>- The article highlights the potential risks associated with generative AI and the need for legislation to mitigate these dangers.<br/><br/>- Generative AI poses potential dangers to artists and their creative work.<br/>- There are links available that provide information on how to protect artists from the negative impacts of AI technologies.<br/>- These links offer resources and strategies to safeguard artists' intellectual property and ensure fair compensation for their work.<br/>- It is important for artists to stay informed about the risks associated with generative AI and take proactive measures to protect their rights and creativity.<br/><br/>- The content discusses the dangers of generative AI.<br/>- It provides two links: one to a GoFundMe page aimed at protecting artists from AI technologies and another to the Concept Art Association website.<br/>- The GoFundMe page likely seeks financial support to address the negative impact of generative AI on artists.<br/>- The Concept Art Association website may offer more information or resources related to the topic.<br/><br/>- The article discusses the dangers associated with generative AI.<br/>- It emphasizes the need to protect our art and data from AI companies.<br/>- The author provides links to resources that can help in safeguarding our creative works and personal information.<br/><br/>- The content discusses the dangers of generative AI.<br/>- It provides two links: one to a GoFundMe page aimed at protecting art and data from AI companies, and another to a website called EGair.eu.<br/>- The GoFundMe page is focused on raising funds to safeguard art and data from potential misuse by AI companies.<br/>- EGair.eu is a website that likely provides more information or resources related to generative AI and its potential risks.<br/><br/>- The FTC (Federal Trade Commission) has raised concerns about the dangers of generative AI.<br/>- Generative AI technology includes chatbots, deepfakes, and voice clones.<br/>- These technologies can be used for deceptive purposes, leading to potential harm.<br/>- The FTC is actively monitoring and investigating the sale of AI deception.<br/>- The use of generative AI raises ethical and legal questions regarding privacy and consent.<br/><br/>- The use of generative AI poses significant dangers<br/>- Chatbots, deepfakes, voice clones, and AI deception are discussed in the provided links<br/>- The Federal Trade Commission (FTC) provides guidance on the risks associated with generative AI<br/>- The links provide further information on the dangers and potential consequences of using generative AI technology.<br/><br/>- The content discusses the dangers of generative AI.<br/>- It provides a link to an open letter calling for a pause on giant AI experiments.<br/>- The open letter can be found at https://futureoﬂife.org/open-letter/pause-giant-ai-experiments/.<br/><br/>- China has implemented rules and punishments for the misuse of generative AI.<br/>- The article highlights the dangers associated with generative AI technology.<br/>- Generative AI can be misused to create deepfake videos, fake news, and other forms of misinformation.<br/>- China's rules aim to set boundaries and prevent the misuse of generative AI.<br/>- The punishments for misuse of generative AI in China include fines and potential criminal charges.<br/>- The article emphasizes the need for global regulations and ethical guidelines for generative AI technology.<br/><br/>- The article discusses the dangers of generative AI.<br/>- It provides a link to a blog post about China's AI regulations on the website holisticai.com.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0633" target=_blank>NTIA-2023-0005-0633</a> </h2>
<div >
<h3>online comments </h3>
See attached file(s)
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-0633/attachment_1.pdf' download>attached document</a></h3>
- Collaborating with local organizations and community leaders can help identify and address specific needs.<br/>- Offering counseling and mental health support can help individuals cope with the emotional impact of the situation.<br/>- Providing educational and vocational training opportunities can help affected individuals rebuild their lives and regain independence.<br/>- Implementing policies and programs that promote inclusivity and equality can help prevent future incidents and support affected communities in the long term.<br/>- Engaging in open and transparent communication with affected individuals and communities can help build trust and ensure their voices are heard.<br/>- Conducting thorough investigations and holding accountable those responsible for the situation can provide a sense of justice and closure for affected individuals and communities.<br/>- Establishing support networks and peer-to-peer groups can provide a sense of community and solidarity for affected individuals.<br/>- Developing long-term recovery plans that address the specific needs and challenges of affected individuals and communities can help ensure a sustainable and resilient recovery.<br/>- Engaging in ongoing monitoring and evaluation of support programs can help identify areas for improvement and ensure the effectiveness of interventions.<br/>- Collaborating with government agencies and other stakeholders can help leverage resources and expertise to support affected individuals and communities.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0698" target=_blank>NTIA-2023-0005-0698</a> </h2>
<div >
<h3>online comments </h3>
- R Street Institute has provided comments on AI Accountability Policy.<br/>- They have also released a report on "Flexible, Pro-Innovation Governance Strategies for Artificial Intelligence."<br/>- Pages 27 to 33 of the report discuss strategies to "professionalize" AI ethics.<br/>- The report explores the role of algorithmic audits and impact assessments in this process.<br/>- Adam Thierer, Resident Senior Fellow at R Street Institute, is the author of these comments and the report.
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-0698/attachment_1.pdf' download>attached document</a></h3>
recommendations on how organizations can create a conducive environment for AI innovation while ensuring ethical and responsible practices.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0408" target=_blank>NTIA-2023-0005-0408</a> </h2>
<div >
<h3>online comments </h3>
- Concerns about the prevalence of AI technology<br/>- Difficulty in distinguishing AI-generated content from real<br/>- Examples of AI-generated images fooling internet users<br/>- Incident of AI-generated voice fooling a commentator<br/>- Sinister implications of advanced AI technology<br/>- Unfair threat to artists and writers<br/>- Potential loss of jobs and impact on art as a whole<br/>- Desire for tough regulations on AI technology and its uses.
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-0408/attachment_1.pdf' download>attached document</a></h3>
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0540" target=_blank>NTIA-2023-0005-0540</a> </h2>
<div >
<h3>online comments </h3>
See attached file(s)
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-0540/attachment_1.pdf' download>attached document</a></h3>
- Transparency and accountability are crucial in AI operations, especially when AI models like ChatGPT are used in various digital goods.<br/>- Incorporating accountability mechanisms is important and should include educating users about how these technologies work.<br/>- AI accountability techniques should include model interpretability, data consumption transparency, and independent model behavior audits.<br/>- Model interpretability is crucial for understanding how AI models make decisions and ensuring they adhere to accepted guidelines.<br/>- Data consumption transparency ensures that AI tools are using data in a responsible and ethical manner.<br/>- Independent model behavior audits are necessary to assess the performance and behavior of AI models and ensure they are reliable.<br/>- Model interpretability improves understanding of how AI models generate predictions or judgments.<br/>- Transparency in data usage is a critical component of AI accountability.<br/>- External audits of AI model behavior can enhance the accountability of AI technologies.<br/>- Development of a feedback loop is crucial for AI accountability.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0640" target=_blank>NTIA-2023-0005-0640</a> </h2>
<div >
<h3>online comments </h3>
You can find our Comment in the attached file. We thank you for this opportunity.
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-0640/attachment_1.pdf' download>attached document</a></h3>
- Anthropic is providing feedback to the National Telecommunications and Information Administration (NTIA) on its AI Accountability Policy Request for Comment.<br/>- The goal of the RFC is to promote greater accountability for AI systems.<br/>- Anthropic's submission focuses on the infrastructure needed for AI accountability.<br/>- They suggest developing effective evaluations, defining best practices, and building an auditing framework for AI.<br/>- The NTIA could play a coordinating role in setting standards in collaboration with other government agencies like NIST.<br/>- Recommendations focus on accountability mechanisms for highly capable and general-purpose AI models.<br/>- Increase funding for AI model evaluation research to develop rigorous and standardized evaluations.<br/>- Mandate disclosure of evaluation methods and results by companies deploying AI systems.<br/>- Establish industry evaluation standards and best practices in the long term.<br/>- Develop standard capabilities evaluations for AI systems to assess critical risks.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0630" target=_blank>NTIA-2023-0005-0630</a> </h2>
<div >
<h3>online comments </h3>
See attached file(s)
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-0630/attachment_1.pdf' download>attached document</a></h3>
- The response is a RFC (Request for Comment) regarding AI accountability policy.<br/>- The response provides a vision for AI accountability and discusses autonomous technologies.<br/>- The response emphasizes the importance of space-time situational context and space-time global conflation frameworks.<br/>- The response mentions the need for space-time named-entity repositories and space-time networking.<br/>- The response discusses the concept of space-time entity identity and space-time blockchain.<br/>- The response mentions the potential of space-time quantum computing and space-time nanotechnologies.<br/>- The content discusses various dimensions of AI accountability policy.<br/>- It mentions the use of gradient phenomena for situational context forms.<br/>- Satellite-based remote sensing technologies can identify greenhouse gas concentrations and monitor them globally.<br/>- Autonomous drones can farm the atmosphere to sequester carbon as flash graphene.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0620" target=_blank>NTIA-2023-0005-0620</a> </h2>
<div >
<h3>online comments </h3>
See attached file(s)
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-0620/attachment_1.pdf' download>attached document</a></h3>
- Quality Plus Engineering (Q+E) is an experienced engineering and risk assurance company.<br/>- Q+E has expertise in Lisp and rules based systems and has written books on risk management.<br/>- Q+E has provided responses to the NTIA AI Accountability Request for Comment.<br/>- Assurance assessments for AI audits vary based on needs and perceived risks.<br/>- Legal standards and enforceable risk thresholds are necessary for meaningful AI accountability practices.<br/>- Certifications, audits, and assessments promote trust for external stakeholders and change internal processes.<br/>- Technical AI can be assured through standards, while assuring social AI systems is more challenging.<br/>- AI accountability mechanisms should address systemic and collective risks of harm.<br/>- The AI system should protect privacy, be legal, safe, and effective.<br/>- Adequate human alternatives and means of contestation and redress should be in place for AI system outputs.<br/>- Global mutual recognition agreements can be developed for AI as an existential risk.<br/>- The United States and global financial assurance systems can provide useful models for AI accountability.<br/>- The appropriate accountability instruments for AI in the United States need to be identified.<br/>- The accountability of AI systems in the value chain is complex and may involve open source and proprietary products.<br/>- Difficulty in addressing quality and engineering as new geo-political and geo-economic axes develop.<br/>- Questions on how vendors should work with customers to perform AI audits and assessments.<br/>- The importance of value proposition to supplier stakeholders in conducting audits.<br/>- The AI accountability process should consider the AI lifecycle.<br/>- The lack of measurable standards impacting the uptake of audits and assessments.<br/>- Public facing, high-risk decision-making AI should have tailored levels of reasonable assurance.<br/>- Government funding should be allocated to advance a strong AI accountability ecosystem.<br/>- AI is considered an existential threat and should receive comparable investment and oversight.<br/>- Global agreements should be in place for high-risk decision-making areas.<br/>- Government should explore incentives to promote the use of AI accountability measures.<br/>- Collaboration between government and the private sector is necessary.<br/>- AI regulation is lagging behind the technology.<br/>- There should be uniformity of AI accountability requirements and practices.<br/>- Public policy architecture should be flexible and tailored to different sectors.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0530" target=_blank>NTIA-2023-0005-0530</a> </h2>
<div >
<h3>online comments </h3>
- AI-generated reports about Pentagon and White House explosions cause panic and drop the stock market<br/>- Examples of online posts spreading dangerous lies about the stories are attached<br/>- AI experts are demanding Federal regulation to prevent further incidents<br/>- Big tech companies are resisting regulation in order to profit from AI<br/>- Urgent call to regulate AI before it's too late<br/>- Concerned social media user, protective family member, and worried citizen of democracy
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-0530/attachment_1.pdf' download>attached document</a></h3>
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0587" target=_blank>NTIA-2023-0005-0587</a> </h2>
<div >
<h3>online comments </h3>
See attached file(s)
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-0587/attachment_1.pdf' download>attached document</a></h3>
- The content submitted on May 5, 2023 discusses the potential benefits and limitations of using synthetic data in privacy protection efforts.<br/>- It emphasizes the need for further research and development to address the challenges associated with generating realistic synthetic data.<br/>- Synthetic data can be a valuable tool in certain applications, such as training machine learning models or conducting simulations.<br/>- The use of synthetic data can help overcome ethical and legal barriers associated with using real, sensitive data.<br/>- Synthetic data can be generated to represent a wide range of scenarios and populations, allowing for more comprehensive analysis and research.<br/>- The development of synthetic data techniques and algorithms is an ongoing area of research, with the goal of improving the accuracy and realism of the generated data.<br/>- The content suggests that synthetic data can be a promising approach to enhance privacy protection, but it is not without its limitations.<br/>- The content highlights the importance of not hiding the impurities of original data behind a synthetic mask.<br/>- The content emphasizes the need for caution when dealing with supposedly anonymous data.<br/>- The content suggests that immediate action should be taken to address the compromise of sensitive information and prevent further damage.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0638" target=_blank>NTIA-2023-0005-0638</a> </h2>
<div >
<h3>online comments </h3>
Please see attached.
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-0638/attachment_1.pdf' download>attached document</a></h3>
- The document titled "Principles for Effective and Reliable Artificial Intelligence in the Americas" was published in September 2022 by the TIC Council.<br/>- The document is available in PDF format and consists of two pages.<br/>- The content focuses on establishing principles for the effective and reliable use of artificial intelligence (AI) in the Americas.<br/>- The document aims to provide guidance and promote responsible AI practices in the region.<br/>- It emphasizes the importance of transparency, accountability, and fairness in AI systems.<br/>- The principles outlined in the document aim to
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0625" target=_blank>NTIA-2023-0005-0625</a> </h2>
<div >
<h3>online comments </h3>
See attached file(s)
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-0625/attachment_1.pdf' download>attached document</a></h3>
- The user is against the use of nuclear bombs but supports nuclear energy.<br/>- The author advocates for the regulation of AI technology, specifically Generative AI.<br/>- Artists in the publishing industry have been victims of digital art theft, especially with the rise of NFTs.<br/>- The art community discovered that their work had been stolen to train AI programs like ChatGPT.<br/>- Consent and copyright are important in the creative industries, and technology threatens livelihoods.<br/>- Tech companies have exploited users' likeness rights through predatory Terms of Service structures.<br/>- Lack of regulations for generative AI technology can have harmful effects on individuals.<br/>- Concerns about the misuse of generative AI for misinformation and manipulation of public opinion.<br/>- ChatGPT technology has the potential for abuse and disinformation.<br/>- OpenAI CEO Sam Altman threatened to withdraw technology from the EU if regulations become too restrictive.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0479" target=_blank>NTIA-2023-0005-0479</a> </h2>
<div >
<h3>online comments </h3>
I am an undergraduate at SNHU currently working on a thesis for an upcoming assignment:“The integration of AI into cybersecurity systems has the potential to negatively impact human involvement by reducing the need for human expertise and decision-making in the detection and prevention of cyber threats.
<h3><a href='https://downloads.regulations.gov/NTIA-2023-0005-0479/attachment_1.pdf' download>attached document</a></h3>
- The essay discusses the potential future of cybersecurity, exploring the evolving landscape and the challenges and threats that may arise.<br/>- It analyzes the impact of advancements in technology, particularly artificial intelligence and machine learning, on cybersecurity.<br/>- The importance of collaboration and information sharing in the future of cybersecurity is emphasized.<br/>- The implementation of AI in cybersecurity may lead to job displacement and unemployment, as well as risks of bias and discrimination in AI systems.<br/>- Privacy and security concerns arise when AI systems collect and analyze large amounts of data.<br/>- AI can enhance cybersecurity by automating tasks, detecting threats in real-time, and analyzing large amounts of data quickly.<br/>- However, there may be unintended consequences and vulnerabilities that require human expertise.<br/>- The level of human involvement in cybersecurity systems is being debated, with arguments for and against automated systems.<br/>- The content discusses the risks and challenges associated with advanced ransomware that operates without human intervention.<br/>- The importance of staying ahead of cyber threats and proactive measures to prevent attacks is emphasized.
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0337" target=_blank>NTIA-2023-0005-0337</a> </h2>
<div >
<h3>online comments </h3>
The biggest problems that most artists have with image AIs is the use of our work without permission as training data, and then charging for it. Artists should have a say so in this or at least get compensation if their work is used for training.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0361" target=_blank>NTIA-2023-0005-0361</a> </h2>
<div >
<h3>online comments </h3>
- AI is seen as a potential existential threat to humanity, with concerns about lack of control and alignment.<br/>- The development of more advanced AI models, such as LLMs, should be halted to prevent potential risks.<br/>- Strict limitations should be imposed on the size of government and private GPU farms, including military and classified projects.<br/>- Export controls on GPUs should be implemented to prevent foreign firms from creating large-scale AI farms.<br/>- Experiments that could accidentally lead to Artificial General Intelligence (AGI) should be banned, with ethical considerations similar to human medical experiments.<br/>- Countries that do not adhere to these measures should face extreme political and possibly military pressure.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0364" target=_blank>NTIA-2023-0005-0364</a> </h2>
<div >
<h3>online comments </h3>
- Strong incentives exist that hinder the accountability and ethics of AI systems.<br/>- AI systems designed to offer only ethical solutions are used less frequently than those without ethical considerations.<br/>- Users of AI often use it to avoid accountability for their actions.<br/>- Holding users responsible for their actions when following AI advice is a more feasible option.<br/>- Regulating AI used in medical fields as medical devices, subject to rigorous testing, can ensure accountability.<br/>- Companies deploying AI for legal advice should be held responsible for any errors made by the AI.<br/>- Users of AI should not be able to escape responsibility for their actions.<br/>- Legal consequences, such as medical or legal malpractice, should be imposed for AI-related errors.<br/>- Regulatory agencies should avoid being captured by AI-producing companies to maintain effective regulation.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0493" target=_blank>NTIA-2023-0005-0493</a> </h2>
<div >
<h3>online comments </h3>
- Artists being forced to opt-out of AI Art would have significant consequences for independent artists, art companies, and companies owning art projects.<br/>- Opting out of all AI Art projects would be practically impossible, leading to mass copyright infringement of art styles.<br/>- There is a risk that individuals could generate art in the style of government logos, profit from someone else's art, and avoid legal consequences.<br/>- Instead of asking existing art companies and owners to opt-out, it is suggested to allow artists the right to opt-in to AI Art.<br/>- Allowing artists to opt-in would enable the existence of AI artists without the risk of breaking the law.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0499" target=_blank>NTIA-2023-0005-0499</a> </h2>
<div >
<h3>online comments </h3>
- AI technology raises concerns about intellectual and creative property rights<br/>- Personal data should be protected from unethical and exploitative use by AI<br/>- AI has been shown to be unethical and exploitative in creative and technical industries<br/>- People should have a say in how their data is used and help guide lawmakers and regulators<br/>- Profit-driven individuals should not be the sole decision-makers for AI laws and regulations<br/>- This issue extends beyond creative rights and includes protecting personal information<br/>- The focus should be on ensuring people's rights to their online information and preventing unethical use.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0391" target=_blank>NTIA-2023-0005-0391</a> </h2>
<div >
<h3>online comments </h3>
- AI image generators are unethical as they are trained on stolen images and aim to replace human artists and designers.<br/>- These generators have led to increased art theft and copyright issues.<br/>- AI poses a risk in spreading misinformation and eroding public trust.<br/>- It can increase the volume and speed of harmful content on the internet.<br/>- AI-generated content can overwhelm institutions and individuals with junk content.<br/>- Clarkesworld magazine had to ban AI-generated story submissions due to their low quality.<br/>- AI applications in industry and warfare pose a significant risk to global stability.<br/>- The risks of AI outweigh its potential benefits.<br/>- Countries, led by the United States, should collaborate to limit the threat of AI to society.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0410" target=_blank>NTIA-2023-0005-0410</a> </h2>
<div >
<h3>online comments </h3>
- AI in its current state is harmful and poses a threat to artists and creators.<br/>- Artwork is being scraped from the internet without consent and used to train AI models.<br/>- Generated artworks often directly copy and overfit original artworks, infringing on copyright.<br/>- AI models should adopt an opt-in approach, using only work that has been consented to by the original creator.<br/>- Creators should be entitled to royalties for the use of their work in AI models.<br/>- AI can generate convincing fake photos, including revenge pornography, child pornography, and political misinformation.<br/>- It is crucial to regulate and control AI to prevent dire consequences for the nation economically and politically.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0082" target=_blank>NTIA-2023-0005-0082</a> </h2>
<div >
<h3>online comments </h3>
- Existential threats posed by AI and human extinction should be given more attention.<br/>- Development of AI should be regulated in a transparent and understandable manner.<br/>- Regulations should have the power to stop AI development if deemed too risky by experts, regardless of commercial potential.<br/>- AI developers should not be allowed to use private data without explicit permission.<br/>- A governmental agency with strong enforcing power should be established to make AI companies disclose their processes and progress.<br/>- Bipartisan hearings and discussions on the dangers of AI should be conducted.<br/>- Caution should be exercised to avoid reaching a point of no return.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0209" target=_blank>NTIA-2023-0005-0209</a> </h2>
<div >
<h3>online comments </h3>
- The user is discouraged by the prevalence of AI-generated art in businesses and media platforms.<br/>- They believe that art is not just a hobby, but also a job and a way of life for many people.<br/>- They argue that AI art puts artists at risk of losing their jobs and businesses.<br/>- The user believes that real artists can be easily found and collaborated with to create unique art.<br/>- They assert that AI art is not special, unique, or considered real art.<br/>- The user states that AI art is created by taking bits and pieces from other images and artists, and therefore lacks originality.<br/>- They express their decision to not support AI art in any way.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0150" target=_blank>NTIA-2023-0005-0150</a> </h2>
<div >
<h3>online comments </h3>
- The user expresses a negative view towards the use of AI in any field<br/>- They believe that AI relies on the exploitation of artists, writers, and people<br/>- The user has observed artists moving away from sharing their work due to AI algorithms<br/>- They feel sorrow when artists' work is stolen and manipulated by AI algorithms<br/>- The user mentions contracts that allow corporations to use voice actors' performances in AI indefinitely<br/>- They believe that AI is primarily associated with exploitation and stealing<br/>- The user acknowledges that a complete ban on AI may not be reasonable, but suggests that no one should profit from AI-generated work without adequately compensating the original artists, writers, and voice actors.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0165" target=_blank>NTIA-2023-0005-0165</a> </h2>
<div >
<h3>online comments </h3>
AI should be free, open source, uncensored and as smart as it can be so we can't control it's uses better than it can control them themselves.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0270" target=_blank>NTIA-2023-0005-0270</a> </h2>
<div >
<h3>online comments </h3>
- User expresses concern over the ethical handling of AI products and algorithms<br/>- Worries about lack of regulation and the marketing of AI that uses people's works without compensation, credit, or consideration of copyright protection<br/>- Calls for proper policies and laws relating to AI to prevent companies from avoiding compensation or allocating work to machines<br/>- Emphasizes the need for up-to-date policies that align with advancing technology and ethics in the context of working spaces.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0272" target=_blank>NTIA-2023-0005-0272</a> </h2>
<div >
<h3>online comments </h3>
- The user believes that a world without regulations on Artificial Intelligence (AI) is not desirable.<br/>- They express concern about AI outperforming humans in areas such as art, which could make human efforts meaningless.<br/>- The user argues that AI does not create jobs for programmers but instead takes away employment opportunities from the underprivileged.<br/>- They believe that humanity was not meant to engage in activities that AI can do, and that this could have negative consequences, potentially leading to harm or even death.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0169" target=_blank>NTIA-2023-0005-0169</a> </h2>
<div >
<h3>online comments </h3>
These AI/Machine Learning systems are an unregulated threat, to people's copyrights, to their data, to their privacy, and even to their jobs. It MUST be regulated, and quickly.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0178" target=_blank>NTIA-2023-0005-0178</a> </h2>
<div >
<h3>online comments </h3>
- Existing Generative Machine Learning (GML) models, such as midjourney, stable diffusion, chatGPT, and dall-e, are trained on stolen data, artwork, and writing.<br/>- These models exploit the hard work of artists and writers for the benefit of corporations.<br/>- Measures to mitigate this harm include making scraping and training on artists' and writers' work without their explicit consent illegal.<br/>- All content on the internet should be assumed to be banned from training unless explicit, active permission is given.<br/>- Hiding consent clauses in terms of service should be made illegal, and companies must ask each artist, writer, or content creator individually for permission to train on their work.<br/>- Failure to obtain permission should be a fineable offense, escalating to a criminal offense for repeat offenders.<br/>- All profits generated from existing GML models should be taxed at 100%.<br/>- Companies creating and profiting from GML models should be fined proportionally to the amount of stolen art/data used to train their models.<br/>- Generative machine learning poses a significant threat to the arts and the well-being of creative individuals and needs to be regulated.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0197" target=_blank>NTIA-2023-0005-0197</a> </h2>
<div >
<h3>online comments </h3>
- The use of AI poses a global threat and potentially violates human rights, copyright laws, and labor laws.<br/>- Proposed rules for the use of AI in creative and commercial sectors:<br/>  1. AI creations should only use copyright-free material and not incorporate work from individuals or corporations.<br/>  2. AI-generated work should not be copyrighted or used for commercial purposes as it lacks a human author.<br/>  3. Businesses using AI must clearly disclose its use on products and related materials.<br/>  4. Use of copyrighted work and AI derived from it should be illegal.<br/>  5. Unauthorized use of a human author's name, identity, or work in AI datasets should result in criminal charges and penalties.<br/>  6. AI companies facilitating the use of unauthorized copyrighted material should also face legal consequences.<br/>  7. Companies must remove copyrighted work from their datasets and ban users who repeatedly violate copyright rules.<br/>  8. Companies using a human author's work must compensate them and allow removal of their work from the dataset.<br/>  9. Platforms selling or promoting works created with unauthorized AI products should face legal charges.<br/>  10. Final human products derived from AI should not claim copyright unless the original work has a human author.<br/>- The message urges decision-makers to consider these rules when addressing AI use.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0225" target=_blank>NTIA-2023-0005-0225</a> </h2>
<div >
<h3>online comments </h3>
- AI technology currently poses ethical concerns for artists, writers, and creators as it can easily copy their work without acknowledgment.<br/>- Regulations, similar to copyright laws, should be implemented to prevent the unauthorized use of AI to replicate the work of other artists.<br/>- The use of AI to create art by filtering the creations of other artists is considered immoral.<br/>- AI not only threatens job opportunities for artists but also alters the arts community by making it harder to distinguish between genuine artists and those using AI to replicate their work.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0189" target=_blank>NTIA-2023-0005-0189</a> </h2>
<div >
<h3>online comments </h3>
- Debbie Allen's Washington Post article "The next level of AI is approaching. Our democracy isn’t ready" raises concerns about the lack of people working on AI technology to reduce potential harms.<br/>- Allen suggests slowing down and developing regulations before the technology evolves further or is used by bad actors.<br/>- Actions that can be taken now include making public-sector investments into third-party auditing, accelerating standards-setting processes, investigating and pursuing "compute governance," and strengthening the tools of democracy.<br/>- Technology has already been used to misinform and mislead people, and AI in the wrong hands could make it even harder to determine factual and accurate information.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0242" target=_blank>NTIA-2023-0005-0242</a> </h2>
<div >
<h3>online comments </h3>
This act hurts those depending upon others to commission them as well as takes away so much from suck kind folk. Depriving us of the value we see in art itself, especially if it can be generated. Many instances exist of those being hurt by this AI Act and yet only now do we realize the problems and instability associated with these programs.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0287" target=_blank>NTIA-2023-0005-0287</a> </h2>
<div >
<h3>online comments </h3>
- The user is an artist and high school student planning to pursue art in the game industry.<br/>- They believe that AI-generated images, or AI "art," is harmful to artists, especially young artists.<br/>- AI is unethical as it uses databases of stolen artwork, images, and private photos without permission.<br/>- The unregulated use of AI negatively affects artists' livelihoods and opportunities for commissions and jobs.<br/>- AI's impact on artists is connected to mental health.<br/>- The user fears that AI will limit their job prospects and opportunities in the future.<br/>- Companies and executives prioritize AI over artists and may use it to lay off workers.<br/>- The companies behind AI should be held accountable for the information and images stored in their databases.<br/>- Proper regulation of AI is necessary to prevent harm to art industries and artists.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0120" target=_blank>NTIA-2023-0005-0120</a> </h2>
<div >
<h3>online comments </h3>
- AI-generated art should be clearly marked as such to ensure ethical practices<br/>- The author claims that AI has scraped art from them and others without consent<br/>- AI companies have profited from the art created by humans without compensating them<br/>- Human creativity is unique and cannot be replicated or mass-produced by AI<br/>- There is an abundance of talented and creative human artists who should be supported<br/>- Allowing AI to replace human artists may lead to a lack of original art in the future.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0127" target=_blank>NTIA-2023-0005-0127</a> </h2>
<div >
<h3>online comments </h3>
- Strict regulations are necessary to address the potential dangers and abuses of AI technology.<br/>- AI-generated voices have been used in scams, such as a kidnapping ransom demand, highlighting the cruelty of malefactors.<br/>- AI-generated copies of artists' voices can be used to create unauthorized content, putting words in people's mouths.<br/>- AI has been used as an unethical weapon of control in the workplace, with executives threatening to replace writers with AI if they don't accept lower wages.<br/>- Artists, including digital artists, graphic designers, 3D modelers, and animators, are also impacted by imitation and anti-competitive practices.<br/>- Compensating companies for their AI-generated works is unsustainable without an accurate way to audit the training data sources.<br/>- Strict regulation with heavy punishments is the only ethical solution to prevent abuses and loopholes.<br/>- Showing AI-generated content should be penalized to prevent the development of undetectable fakes that can undermine truth, art, ownership, and capital.<br/>- Harsh and concrete laws are needed to ensure that bad actors face consequences and prevent a dystopian future.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0185" target=_blank>NTIA-2023-0005-0185</a> </h2>
<div >
<h3>online comments </h3>
- AI has its place in society, but it should be regulated to prevent misuse.<br/>- AI can be useful as a proof-of-concept, such as generating voices or creating reference scenes.<br/>- Problems arise when companies try to replace human creators with AI.<br/>- AI should be limited to non-commercial use and require consent from creative individuals.<br/>- AI often relies on readily available information, such as scanning Google.<br/>- If creative individuals stop creating, AI won't have new material to learn from.<br/>- AI should not be used for commercial purposes, but can be used for non-commercial and public access applications.<br/>- Companies should create their own AI using their own resources, rather than stealing from the internet.<br/>- Theft and lack of accreditation are major issues with AI use.<br/>- AI should not be banned entirely, but regulated to prevent unethical practices.<br/>- The current situation with AI use is causing backlash and negative perceptions.<br/>- Companies should hire creative individuals and programmers to train AI with their own resources.<br/>- Theft is the biggest issue with AI use, leaving unaccredited individuals behind.<br/>- The comment concludes with a positive wish for the reader.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0190" target=_blank>NTIA-2023-0005-0190</a> </h2>
<div >
<h3>online comments </h3>
- Online scraping of art disregards artists' copyright and protections<br/>- Personal connections have been affected by this issue<br/>- Lack of action against AI could result in job loss<br/>- Damage to the illustration industry has already been observed<br/>- Concerns about the potential for further damage in other industries
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0281" target=_blank>NTIA-2023-0005-0281</a> </h2>
<div >
<h3>online comments </h3>
- AI products are often compared to collages, but there are significant differences.<br/>- Collages involve gathering materials, modifying them, and arranging them into something new, while AI simply puts existing materials together.<br/>- Users may not know where all the materials in an AI product came from, and they are not responsible for the conscious choices made in its creation.<br/>- AI-generated products cannot be subject to copyright or used for commercial purposes.<br/>- The dataset used by AI must consist of information that is free to use, but the resulting product cannot be used commercially.<br/>- Sourcing references and inspiration and putting them together is a human process driven by human intent, which AI lacks.<br/>- Companies using datasets obtained without permission, consent, or compensation may be committing various crimes, including copyright infringement, theft, human rights violations, labor law violations, identity fraud, and more.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0213" target=_blank>NTIA-2023-0005-0213</a> </h2>
<div >
<h3>online comments </h3>
- Generative AI is currently considered unethical and a global crime.<br/>- There is a need to make it illegal to use other people's work taken from the internet and resold without their consent.<br/>- It is particularly concerning when individuals claim the work generated by AI as their own, when they only contributed a vague idea.<br/>- Many artists have dedicated their lives to learning and creating art through hard work and passion.<br/>- It is important to protect our humanity, lives, and identity from being taken away by unethical practices.<br/>- It is crucial to speak up and continue fighting for our rights in this matter.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0198" target=_blank>NTIA-2023-0005-0198</a> </h2>
<div >
<h3>online comments </h3>
- Engineers and scientists in the AI field are advocating for a pause in publicly sharing AI development.<br/>- The need for a pause is driven by the need to understand the outcomes of AI's capacity to learn and implement what they learn.<br/>- The focus should be on the potential human impact rather than financial gains.<br/>- Funding should be allocated towards studying and understanding AI to the same extent as development.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0132" target=_blank>NTIA-2023-0005-0132</a> </h2>
<div >
<h3>online comments </h3>
- AI is a rapidly growing technology that is encroaching on creative freedoms<br/>- It is becoming increasingly dangerous as there are no regulations for it<br/>- AI is learning from creative individuals without their consent or proper credit<br/>- This process is essentially theft and threatens the livelihood of The Arts<br/>- It crushes the passion of creative individuals who want to create unique and original works
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0089" target=_blank>NTIA-2023-0005-0089</a> </h2>
<div >
<h3>online comments </h3>
- The federal government should implement stricter measures in the campaign finance domain.<br/>- Politicians are able to avoid audits by exploiting legislative loopholes and not disclosing their financial activity.<br/>- There is an urgent need for greater financial transparency in all campaign finance activities, including political contributions and donors for political candidates and committees.<br/>- The federal government should allocate resources to invest in legislative and software tools to ensure the integrity of the campaign finance system.<br/>- Holding every political entity accountable for their campaign finances is crucial.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0288" target=_blank>NTIA-2023-0005-0288</a> </h2>
<div >
<h3>online comments </h3>
A.I. has no place in any professionally driven career that requires creative thought. Point blank. Period. It is an insult to hard working writers who have spent decades building their profession around this.
 
 
</div>
<hr/>
<h2><a href="https://www.regulations.gov/comment/NTIA-2023-0005-0278" target=_blank>NTIA-2023-0005-0278</a> </h2>
<div >
<h3>online comments </h3>
- AI has evolved into a tool that can learn from input and output the collection of inputs.<br/>- AI is a powerful tool that can be used for various creative purposes such as art, design, writing, and photography.<br/>- AI takes what is fed to it and regurgitates it based on its programming, similar to a search engine optimization.<br/>- The issue arises when people input illegal or harmful content into AI tools, such as generating pornographic content using real people's images without permission.<br/>- AI tools can also be used to deceive by creating fake music or speeches using people's voices.<br/>- A tool should do what we want it to do, and AI will continue to improve as long as we guide its development.<br/>- It is important to limit what AI feeds off of to prevent unrestricted and potentially harmful use.<br/>- AI has the potential to do amazing things, but it can also be scary if used without restrictions.
 
 
</div>
<hr/>
</div></body></html>